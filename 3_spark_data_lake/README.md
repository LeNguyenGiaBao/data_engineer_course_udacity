# Data Lake Project
 
Using data lake and spark to process data from json file, extract data, transform data to and load data to s3 

You need to pass the access key and secret key on aws to run it on s3

## How to run:
- Login AWS account and get access key and secret key
- Pass the access key and secret key to config file `dl.cfg`
- Run `etl.py` file

## Dataset Description
Dataset location:
- Song data: s3://udacity-dend/song_data
- Log data: s3://udacity-dend/log_data

Detail: 
- Song dataset is a subset of real data from the Million Song Dataset. Each file is in JSON format and contains metadata about a song and the artist of that song. The files are partitioned by the first three letters of each song's track ID. For example, here are filepaths to two files in this dataset.
    Example:
    ```
    song_data/A/B/C/TRABCEI128F424C983.json
    song_data/A/A/B/TRAABJL12903CDCF1A.json
    ```
    `{"num_songs": 1, "artist_id": "ARJIE2Y1187B994AB7", "artist_latitude": null, "artist_longitude": null, "artist_location": "", "artist_name": "Line Renaud", "song_id": "SOUPIRU12A6D4FA1E1", "title": "Der Kleine Dompfaff", "duration": 152.92036, "year": 0}`
- Log dataset consists of log files in JSON format generated by this event simulator based on the songs in the dataset above. These simulate app activity logs from an imaginary music streaming app based on configuration settings.
    Example:
    ```
    log_data/2018/11/2018-11-12-events.json
    log_data/2018/11/2018-11-13-events.json
    ```
    