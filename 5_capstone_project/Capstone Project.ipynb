{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# US Immigration Data Analysis\n",
    "### Data Engineering Capstone Project\n",
    "\n",
    "## Project Summary\n",
    "The project is about US Immigration Dataset and the other relevant datasets, with the purpose is to dive into and understand the dataset, build a data model, ETL and data pipeline. \n",
    "\n",
    "Detail of the steps of project:\n",
    "  1. Scope the Project and Gather Data\n",
    "  2. Explore and Assess the Data\n",
    "  3. Define the Data Model\n",
    "  4. Run ETL to Model the Data\n",
    "  5. Complete Project Write Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Do all imports and installs here\n",
    "import pandas as pd\n",
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import isnan, when, count, col, udf, min, max, pandas_udf, PandasUDFType\n",
    "from pyspark.sql.types import IntegerType, LongType, DateType, BooleanType, DoubleType, StringType, StructType, StructField\n",
    "from datetime import datetime, timedelta\n",
    "import glob \n",
    "import tqdm \n",
    "\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "os.environ[\"PATH\"] = \"/opt/conda/bin:/opt/spark-2.4.3-bin-hadoop2.7/bin:/opt/conda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/lib/jvm/java-8-openjdk-amd64/bin\"\n",
    "os.environ[\"SPARK_HOME\"] = \"/opt/spark-2.4.3-bin-hadoop2.7\"\n",
    "os.environ[\"HADOOP_HOME\"] = \"/opt/spark-2.4.3-bin-hadoop2.7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder\\\n",
    "        .config(\"spark.jars.repositories\", \"https://repos.spark-packages.org/\")\\\n",
    "        .config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-aws:2.7.0,saurfang:spark-sas7bdat:2.0.0-s_2.11\")\\\n",
    "        .enableHiveSupport().getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i94_apr16_sub.sas7bdat\ti94_jan16_sub.sas7bdat\ti94_may16_sub.sas7bdat\n",
      "i94_aug16_sub.sas7bdat\ti94_jul16_sub.sas7bdat\ti94_nov16_sub.sas7bdat\n",
      "i94_dec16_sub.sas7bdat\ti94_jun16_sub.sas7bdat\ti94_oct16_sub.sas7bdat\n",
      "i94_feb16_sub.sas7bdat\ti94_mar16_sub.sas7bdat\ti94_sep16_sub.sas7bdat\n"
     ]
    }
   ],
   "source": [
    "!ls ../../data/18-83510-I94-Data-2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# use show_data flag to recude the time to execute the query\n",
    "show_data = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Step 1: Scope the Project and Gather Data\n",
    "\n",
    "### Scope \n",
    "Explain what you plan to do in the project in more detail. What data do you use? What is your end solution look like? What tools did you use? etc>\n",
    "\n",
    "### Data Description\n",
    "The data used in this project included 4 datasets:\n",
    "- [I94 Immigration Data](https://travel.trade.gov/research/reports/i94/historical/2016.html): The dataset about immigration information of US. This data comes from the US National Tourism and Trade Office. More detail [here](https://travel.trade.gov/research/programs/i94/description.asp)\n",
    "- [World Temperature Data](https://www.kaggle.com/berkeleyearth/climate-change-earth-surface-temperature-data): The dataset include temperature, longitude and latitude of the cities in US\n",
    "- [U.S. City Demographic Data](https://public.opendatasoft.com/explore/dataset/us-cities-demographics/export/): The overview information of the cities in US, like sex distribution, population, median age, ...\n",
    "- [Airport Code Data](https://datahub.io/core/airport-codes#data): includes name and other information of the airport in US. The data includes the code, name, type, region, gps code, coordinates, ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Step 2: Explore and Assess the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Explore I94 Immigration Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+\n",
      "|cicid| i94yr|i94mon|i94cit|i94res|i94port|arrdate|i94mode|i94addr|depdate|i94bir|i94visa|count|dtadfile|visapost|occup|entdepa|entdepd|entdepu|matflag|biryear| dtaddto|gender|insnum|airline|        admnum|fltno|visatype|\n",
      "+-----+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+\n",
      "|  6.0|2016.0|   4.0| 692.0| 692.0|    XXX|20573.0|   null|   null|   null|  37.0|    2.0|  1.0|    null|    null| null|      T|   null|      U|   null| 1979.0|10282016|  null|  null|   null| 1.897628485E9| null|      B2|\n",
      "|  7.0|2016.0|   4.0| 254.0| 276.0|    ATL|20551.0|    1.0|     AL|   null|  25.0|    3.0|  1.0|20130811|     SEO| null|      G|   null|      Y|   null| 1991.0|     D/S|     M|  null|   null|  3.73679633E9|00296|      F1|\n",
      "| 15.0|2016.0|   4.0| 101.0| 101.0|    WAS|20545.0|    1.0|     MI|20691.0|  55.0|    2.0|  1.0|20160401|    null| null|      T|      O|   null|      M| 1961.0|09302016|     M|  null|     OS|  6.66643185E8|   93|      B2|\n",
      "| 16.0|2016.0|   4.0| 101.0| 101.0|    NYC|20545.0|    1.0|     MA|20567.0|  28.0|    2.0|  1.0|20160401|    null| null|      O|      O|   null|      M| 1988.0|09302016|  null|  null|     AA|9.246846133E10|00199|      B2|\n",
      "| 17.0|2016.0|   4.0| 101.0| 101.0|    NYC|20545.0|    1.0|     MA|20567.0|   4.0|    2.0|  1.0|20160401|    null| null|      O|      O|   null|      M| 2012.0|09302016|  null|  null|     AA|9.246846313E10|00199|      B2|\n",
      "| 18.0|2016.0|   4.0| 101.0| 101.0|    NYC|20545.0|    1.0|     MI|20555.0|  57.0|    1.0|  1.0|20160401|    null| null|      O|      O|   null|      M| 1959.0|09302016|  null|  null|     AZ|9.247103803E10|00602|      B1|\n",
      "| 19.0|2016.0|   4.0| 101.0| 101.0|    NYC|20545.0|    1.0|     NJ|20558.0|  63.0|    2.0|  1.0|20160401|    null| null|      O|      K|   null|      M| 1953.0|09302016|  null|  null|     AZ|9.247139923E10|00602|      B2|\n",
      "| 20.0|2016.0|   4.0| 101.0| 101.0|    NYC|20545.0|    1.0|     NJ|20558.0|  57.0|    2.0|  1.0|20160401|    null| null|      O|      K|   null|      M| 1959.0|09302016|  null|  null|     AZ|9.247161383E10|00602|      B2|\n",
      "| 21.0|2016.0|   4.0| 101.0| 101.0|    NYC|20545.0|    1.0|     NY|20553.0|  46.0|    2.0|  1.0|20160401|    null| null|      O|      O|   null|      M| 1970.0|09302016|  null|  null|     AZ|9.247079603E10|00602|      B2|\n",
      "| 22.0|2016.0|   4.0| 101.0| 101.0|    NYC|20545.0|    1.0|     NY|20562.0|  48.0|    1.0|  1.0|20160401|    null| null|      O|      O|   null|      M| 1968.0|09302016|  null|  null|     AZ|9.247848973E10|00608|      B1|\n",
      "+-----+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_immigration = spark.read.format('com.github.saurfang.sas.spark').load('../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat')\n",
    "df_immigration.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# check null records of column \n",
    "if show_data:\n",
    "    df_immigration.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in df_immigration.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# remove columns that dont use: many rows are null or \"CIC does not use\" description file\n",
    "cols_removed = ['occup', 'entdepu', 'insnum', 'dtadfile', 'visapost', 'entdepa', 'entdepd', 'dtaddto', 'count']\n",
    "df_immigration_dropped = df_immigration.drop(*cols_removed)\n",
    "if show_data:\n",
    "    df_immigration_dropped.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cicid: double (nullable = true)\n",
      " |-- i94yr: double (nullable = true)\n",
      " |-- i94mon: double (nullable = true)\n",
      " |-- i94cit: double (nullable = true)\n",
      " |-- i94res: double (nullable = true)\n",
      " |-- i94port: string (nullable = true)\n",
      " |-- arrdate: double (nullable = true)\n",
      " |-- i94mode: double (nullable = true)\n",
      " |-- i94addr: string (nullable = true)\n",
      " |-- depdate: double (nullable = true)\n",
      " |-- i94bir: double (nullable = true)\n",
      " |-- i94visa: double (nullable = true)\n",
      " |-- matflag: string (nullable = true)\n",
      " |-- biryear: double (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- admnum: double (nullable = true)\n",
      " |-- fltno: string (nullable = true)\n",
      " |-- visatype: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_immigration_dropped.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Explore ../../data/18-83510-I94-Data-2016/i94_jun16_sub.sas7bdat data file\n",
    "df_immigration = spark.read.format('com.github.saurfang.sas.spark').load('../../data/18-83510-I94-Data-2016/i94_jun16_sub.sas7bdat')\n",
    "if show_data:\n",
    "    df_immigration.show(10)\n",
    "# i94_jun16_sub has 24 columns --> remove abnormal columns: 'delete_days','delete_mexl','delete_dup','delete_visa','delete_recdup', 'df_world_temp.count()'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Cleaning Step for I94 Immigration Dataset\n",
    "- Drop unnecessary columns\n",
    "- Change data type of columns \n",
    "- Change date type and boolean type of columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def convert_date_from_int(date):\n",
    "    if date is None: \n",
    "        return None \n",
    "    return datetime(1960, 1, 1) + timedelta(days=int(date))\n",
    "udf_convert_date_from_int = udf(lambda x: convert_date_from_int(x), DateType())\n",
    "\n",
    "def convert_match(match):\n",
    "    if str(match) == 'M':\n",
    "        return True\n",
    "    return False\n",
    "udf_convert_match = udf(lambda x: convert_match(x), BooleanType())\n",
    "\n",
    "def normalize_immigration_data(df):  \n",
    "    # drop unnecessary columns\n",
    "    cols_removed = ['occup', 'entdepu', 'insnum', 'dtadfile', 'visapost', 'entdepa', 'entdepd', 'dtaddto', 'count', 'delete_days','delete_mexl','delete_dup','delete_visa','delete_recdup', 'validres']\n",
    "    df = df.drop(*cols_removed)\n",
    "    \n",
    "    # change data type \n",
    "    df = df.withColumn(\"cicid\", df[\"cicid\"].cast(IntegerType()))\n",
    "    df = df.withColumn(\"i94yr\", df[\"i94yr\"].cast(IntegerType()))\n",
    "    df = df.withColumn(\"i94mon\", df[\"i94mon\"].cast(IntegerType()))\n",
    "    df = df.withColumn(\"i94cit\", df[\"i94cit\"].cast(IntegerType()))\n",
    "    df = df.withColumn(\"i94res\", df[\"i94res\"].cast(IntegerType()))\n",
    "    df = df.withColumn(\"i94mode\", df[\"i94mode\"].cast(IntegerType()))\n",
    "    df = df.withColumn(\"i94bir\", df[\"i94bir\"].cast(IntegerType()))\n",
    "    df = df.withColumn(\"i94visa\", df[\"i94visa\"].cast(IntegerType()))\n",
    "    df = df.withColumn(\"biryear\", df[\"biryear\"].cast(IntegerType()))                                                \n",
    "    df = df.withColumn(\"admnum\", df[\"admnum\"].cast(LongType()))\n",
    "    \n",
    "    # change date time type\n",
    "    df = df.withColumn(\"arrdate\", udf_convert_date_from_int(\"arrdate\"))\n",
    "    df = df.withColumn(\"depdate\", udf_convert_date_from_int(\"depdate\"))\n",
    "    \n",
    "    # change match column to boolean type\n",
    "    df = df.withColumn(\"matflag\", udf_convert_match(df[\"matflag\"]))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:09<00:00,  1.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+------+------+------+-------+----------+-------+-------+----------+------+-------+-------+-------+------+-------+-----------+-----+--------+\n",
      "|cicid|i94yr|i94mon|i94cit|i94res|i94port|   arrdate|i94mode|i94addr|   depdate|i94bir|i94visa|matflag|biryear|gender|airline|     admnum|fltno|visatype|\n",
      "+-----+-----+------+------+------+-------+----------+-------+-------+----------+------+-------+-------+-------+------+-------+-----------+-----+--------+\n",
      "|    6| 2016|     4|   692|   692|    XXX|2016-04-29|   null|   null|      null|    37|      2|  false|   1979|  null|   null| 1897628485| null|      B2|\n",
      "|    7| 2016|     4|   254|   276|    ATL|2016-04-07|      1|     AL|      null|    25|      3|  false|   1991|     M|   null| 3736796330|00296|      F1|\n",
      "|   15| 2016|     4|   101|   101|    WAS|2016-04-01|      1|     MI|2016-08-25|    55|      2|   true|   1961|     M|     OS|  666643185|   93|      B2|\n",
      "|   16| 2016|     4|   101|   101|    NYC|2016-04-01|      1|     MA|2016-04-23|    28|      2|   true|   1988|  null|     AA|92468461330|00199|      B2|\n",
      "|   17| 2016|     4|   101|   101|    NYC|2016-04-01|      1|     MA|2016-04-23|     4|      2|   true|   2012|  null|     AA|92468463130|00199|      B2|\n",
      "|   18| 2016|     4|   101|   101|    NYC|2016-04-01|      1|     MI|2016-04-11|    57|      1|   true|   1959|  null|     AZ|92471038030|00602|      B1|\n",
      "|   19| 2016|     4|   101|   101|    NYC|2016-04-01|      1|     NJ|2016-04-14|    63|      2|   true|   1953|  null|     AZ|92471399230|00602|      B2|\n",
      "|   20| 2016|     4|   101|   101|    NYC|2016-04-01|      1|     NJ|2016-04-14|    57|      2|   true|   1959|  null|     AZ|92471613830|00602|      B2|\n",
      "|   21| 2016|     4|   101|   101|    NYC|2016-04-01|      1|     NY|2016-04-09|    46|      2|   true|   1970|  null|     AZ|92470796030|00602|      B2|\n",
      "|   22| 2016|     4|   101|   101|    NYC|2016-04-01|      1|     NY|2016-04-18|    48|      1|   true|   1968|  null|     AZ|92478489730|00608|      B1|\n",
      "+-----+-----+------+------+------+-------+----------+-------+-------+----------+------+-------+-------+-------+------+-------+-----------+-----+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "immigration_data_paths = glob.glob(\"../../data/18-83510-I94-Data-2016/*.sas7bdat\")\n",
    "df_immigration = None\n",
    "for path in tqdm.tqdm(immigration_data_paths):\n",
    "    df = spark.read.format('com.github.saurfang.sas.spark').load(path)\n",
    "    df = normalize_immigration_data(df)\n",
    "    if df_immigration is None: \n",
    "        df_immigration = df\n",
    "    else:\n",
    "        df_immigration = df_immigration.union(df)\n",
    "    \n",
    "if show_data:\n",
    "    print(\"total records:\", df_immigration.count())\n",
    "    \n",
    "df_immigration.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# is \"cicid\" is unique value\n",
    "if show_data:\n",
    "    num_cicid = df_immigration.select('cicid').count()\n",
    "    num_unique_cicid = df_immigration.select('cicid').distinct().count()\n",
    "\n",
    "    print(\"num_cicid\", num_cicid)\n",
    "    print(\"num_unique_cicid\", num_unique_cicid)\n",
    "\n",
    "    print(\"cicid is unique\", num_cicid == num_unique_cicid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Explore World Temperature Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+-----------------------------+-----+-------+--------+---------+\n",
      "|        dt|AverageTemperature|AverageTemperatureUncertainty| City|Country|Latitude|Longitude|\n",
      "+----------+------------------+-----------------------------+-----+-------+--------+---------+\n",
      "|1743-11-01|             6.068|           1.7369999999999999|Århus|Denmark|  57.05N|   10.33E|\n",
      "|1743-12-01|              null|                         null|Århus|Denmark|  57.05N|   10.33E|\n",
      "|1744-01-01|              null|                         null|Århus|Denmark|  57.05N|   10.33E|\n",
      "|1744-02-01|              null|                         null|Århus|Denmark|  57.05N|   10.33E|\n",
      "|1744-03-01|              null|                         null|Århus|Denmark|  57.05N|   10.33E|\n",
      "|1744-04-01|5.7879999999999985|           3.6239999999999997|Århus|Denmark|  57.05N|   10.33E|\n",
      "|1744-05-01|            10.644|           1.2830000000000001|Århus|Denmark|  57.05N|   10.33E|\n",
      "|1744-06-01|14.050999999999998|                        1.347|Århus|Denmark|  57.05N|   10.33E|\n",
      "|1744-07-01|            16.082|                        1.396|Århus|Denmark|  57.05N|   10.33E|\n",
      "|1744-08-01|              null|                         null|Århus|Denmark|  57.05N|   10.33E|\n",
      "+----------+------------------+-----------------------------+-----+-------+--------+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_world_temp = spark.read.csv('../../data2/GlobalLandTemperaturesByCity.csv', header=True)\n",
    "df_world_temp.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "if show_data:\n",
    "    print(\"total records:\", df_world_temp.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# check null record\n",
    "if show_data:\n",
    "    df_world_temp.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in df_world_temp.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dt: string (nullable = true)\n",
      " |-- AverageTemperature: string (nullable = true)\n",
      " |-- AverageTemperatureUncertainty: string (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      " |-- Latitude: string (nullable = true)\n",
      " |-- Longitude: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_world_temp.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# create schema for world temp dataset\n",
    "df_world_temp_schema = StructType([\n",
    "    StructField('dt', DateType(), True),\n",
    "    StructField('AverageTemperature', DoubleType(), True),\n",
    "    StructField('AverageTemperatureUncertainty', DoubleType(), True),\n",
    "    StructField('City', StringType(), True),\n",
    "    StructField('Country', StringType(), True),\n",
    "    StructField('Latitude', StringType(), True),\n",
    "    StructField('Longitude', StringType(), True)\n",
    "])\n",
    "\n",
    "# re read world temp data \n",
    "df_world_temp = spark.read.csv('../../data2/GlobalLandTemperaturesByCity.csv', schema=df_world_temp_schema, header=True)\n",
    "if show_data:\n",
    "    df_world_temp.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+-----------------------------+-----+-------+--------+---------+\n",
      "|        dt|AverageTemperature|AverageTemperatureUncertainty| City|Country|Latitude|Longitude|\n",
      "+----------+------------------+-----------------------------+-----+-------+--------+---------+\n",
      "|1743-11-01|             6.068|           1.7369999999999999|Århus|Denmark|  57.05N|   10.33E|\n",
      "|1743-12-01|              null|                         null|Århus|Denmark|  57.05N|   10.33E|\n",
      "|1744-01-01|              null|                         null|Århus|Denmark|  57.05N|   10.33E|\n",
      "|1744-02-01|              null|                         null|Århus|Denmark|  57.05N|   10.33E|\n",
      "|1744-03-01|              null|                         null|Århus|Denmark|  57.05N|   10.33E|\n",
      "|1744-04-01|5.7879999999999985|           3.6239999999999997|Århus|Denmark|  57.05N|   10.33E|\n",
      "|1744-05-01|            10.644|           1.2830000000000001|Århus|Denmark|  57.05N|   10.33E|\n",
      "|1744-06-01|14.050999999999998|                        1.347|Århus|Denmark|  57.05N|   10.33E|\n",
      "|1744-07-01|            16.082|                        1.396|Århus|Denmark|  57.05N|   10.33E|\n",
      "|1744-08-01|              null|                         null|Århus|Denmark|  57.05N|   10.33E|\n",
      "+----------+------------------+-----------------------------+-----+-------+--------+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_world_temp.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# how many countries ??\n",
    "if show_data:\n",
    "    df_world_temp.select(\"Country\").distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# what are the start date and the end date?\n",
    "if show_data:\n",
    "    print(\"start date:\", df_world_temp.agg(min(\"dt\")).first()[0])\n",
    "    print(\"end date:\", df_world_temp.agg(max(\"dt\")).first()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Cleaning Step for World Temperature Dataset\n",
    "- Drop unnecessary columns: AverageTemperatureUncertainty, Latitude, Longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------------+-----+-------+\n",
      "|        dt| AverageTemperature| City|Country|\n",
      "+----------+-------------------+-----+-------+\n",
      "|1743-11-01|              6.068|Århus|Denmark|\n",
      "|1743-12-01|               null|Århus|Denmark|\n",
      "|1744-01-01|               null|Århus|Denmark|\n",
      "|1744-02-01|               null|Århus|Denmark|\n",
      "|1744-03-01|               null|Århus|Denmark|\n",
      "|1744-04-01| 5.7879999999999985|Århus|Denmark|\n",
      "|1744-05-01|             10.644|Århus|Denmark|\n",
      "|1744-06-01| 14.050999999999998|Århus|Denmark|\n",
      "|1744-07-01|             16.082|Århus|Denmark|\n",
      "|1744-08-01|               null|Århus|Denmark|\n",
      "|1744-09-01| 12.780999999999999|Århus|Denmark|\n",
      "|1744-10-01|               7.95|Århus|Denmark|\n",
      "|1744-11-01|  4.638999999999999|Århus|Denmark|\n",
      "|1744-12-01|0.12199999999999987|Århus|Denmark|\n",
      "|1745-01-01|-1.3330000000000002|Århus|Denmark|\n",
      "|1745-02-01|             -2.732|Århus|Denmark|\n",
      "|1745-03-01|              0.129|Århus|Denmark|\n",
      "|1745-04-01|              4.042|Århus|Denmark|\n",
      "|1745-05-01|               null|Århus|Denmark|\n",
      "|1745-06-01|               null|Århus|Denmark|\n",
      "+----------+-------------------+-----+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_world_temp = df_world_temp.drop(*['AverageTemperatureUncertainty', 'Latitude', 'Longitude'])\n",
    "df_world_temp.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Explore U.S. City Demographic Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+--------------+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+--------------------+-----+\n",
      "|            City|         State|Median Age|Male Population|Female Population|Total Population|Number of Veterans|Foreign-born|Average Household Size|State Code|                Race|Count|\n",
      "+----------------+--------------+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+--------------------+-----+\n",
      "|   Silver Spring|      Maryland|      33.8|          40601|            41862|           82463|              1562|       30908|                   2.6|        MD|  Hispanic or Latino|25924|\n",
      "|          Quincy| Massachusetts|      41.0|          44129|            49500|           93629|              4147|       32935|                  2.39|        MA|               White|58723|\n",
      "|          Hoover|       Alabama|      38.5|          38040|            46799|           84839|              4819|        8229|                  2.58|        AL|               Asian| 4759|\n",
      "|Rancho Cucamonga|    California|      34.5|          88127|            87105|          175232|              5821|       33878|                  3.18|        CA|Black or African-...|24437|\n",
      "|          Newark|    New Jersey|      34.6|         138040|           143873|          281913|              5829|       86253|                  2.73|        NJ|               White|76402|\n",
      "|          Peoria|      Illinois|      33.1|          56229|            62432|          118661|              6634|        7517|                   2.4|        IL|American Indian a...| 1343|\n",
      "|        Avondale|       Arizona|      29.1|          38712|            41971|           80683|              4815|        8355|                  3.18|        AZ|Black or African-...|11592|\n",
      "|     West Covina|    California|      39.8|          51629|            56860|          108489|              3800|       37038|                  3.56|        CA|               Asian|32716|\n",
      "|        O'Fallon|      Missouri|      36.0|          41762|            43270|           85032|              5783|        3269|                  2.77|        MO|  Hispanic or Latino| 2583|\n",
      "|      High Point|North Carolina|      35.5|          51751|            58077|          109828|              5204|       16315|                  2.65|        NC|               Asian|11060|\n",
      "+----------------+--------------+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+--------------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_us_city = spark.read.csv('./us-cities-demographics.csv', header=True, sep=';')\n",
    "df_us_city.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "if show_data:\n",
    "    print(\"total records:\", df_us_city.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+----+-----+\n",
      "|city|state|median_age|male_population|female_population|total_population|number_of_veterans|foreign_born|average_household_size|state_code|race|count|\n",
      "+----+-----+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+----+-----+\n",
      "|   0|    0|         0|              3|                3|               0|                13|          13|                    16|         0|   0|    0|\n",
      "+----+-----+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check null record\n",
    "if show_data:\n",
    "    df_us_city.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in df_us_city.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- City: string (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- Median Age: string (nullable = true)\n",
      " |-- Male Population: string (nullable = true)\n",
      " |-- Female Population: string (nullable = true)\n",
      " |-- Total Population: string (nullable = true)\n",
      " |-- Number of Veterans: string (nullable = true)\n",
      " |-- Foreign-born: string (nullable = true)\n",
      " |-- Average Household Size: string (nullable = true)\n",
      " |-- State Code: string (nullable = true)\n",
      " |-- Race: string (nullable = true)\n",
      " |-- Count: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_us_city.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+--------------+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+--------------------+-----+\n",
      "|            city|         state|median_age|male_population|female_population|total_population|number_of_veterans|foreign_born|average_household_size|state_code|                race|count|\n",
      "+----------------+--------------+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+--------------------+-----+\n",
      "|   Silver Spring|      Maryland|      33.8|          40601|            41862|           82463|              1562|       30908|                   2.6|        MD|  Hispanic or Latino|25924|\n",
      "|          Quincy| Massachusetts|      41.0|          44129|            49500|           93629|              4147|       32935|                  2.39|        MA|               White|58723|\n",
      "|          Hoover|       Alabama|      38.5|          38040|            46799|           84839|              4819|        8229|                  2.58|        AL|               Asian| 4759|\n",
      "|Rancho Cucamonga|    California|      34.5|          88127|            87105|          175232|              5821|       33878|                  3.18|        CA|Black or African-...|24437|\n",
      "|          Newark|    New Jersey|      34.6|         138040|           143873|          281913|              5829|       86253|                  2.73|        NJ|               White|76402|\n",
      "|          Peoria|      Illinois|      33.1|          56229|            62432|          118661|              6634|        7517|                   2.4|        IL|American Indian a...| 1343|\n",
      "|        Avondale|       Arizona|      29.1|          38712|            41971|           80683|              4815|        8355|                  3.18|        AZ|Black or African-...|11592|\n",
      "|     West Covina|    California|      39.8|          51629|            56860|          108489|              3800|       37038|                  3.56|        CA|               Asian|32716|\n",
      "|        O'Fallon|      Missouri|      36.0|          41762|            43270|           85032|              5783|        3269|                  2.77|        MO|  Hispanic or Latino| 2583|\n",
      "|      High Point|North Carolina|      35.5|          51751|            58077|          109828|              5204|       16315|                  2.65|        NC|               Asian|11060|\n",
      "+----------------+--------------+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+--------------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_us_city_schema = StructType([\n",
    "    StructField('city', StringType(), True),\n",
    "    StructField('state', StringType(), True),\n",
    "    StructField('median_age', DoubleType(), True),\n",
    "    StructField('male_population', IntegerType(), True),\n",
    "    StructField('female_population', IntegerType(), True),\n",
    "    StructField('total_population', IntegerType(), True),\n",
    "    StructField('number_of_veterans', IntegerType(), True),\n",
    "    StructField('foreign_born', IntegerType(), True),\n",
    "    StructField('average_household_size', DoubleType(), True),\n",
    "    StructField('state_code', StringType(), True),\n",
    "    StructField('race', StringType(), True),\n",
    "    StructField('count', IntegerType(), True)\n",
    "])\n",
    "\n",
    "df_us_city = spark.read.csv('./us-cities-demographics.csv', schema=df_us_city_schema, header=True, sep=';')\n",
    "df_us_city.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Explore Airport Code Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------+--------------------+------------+---------+-----------+----------+------------+--------+---------+----------+--------------------+\n",
      "|ident|         type|                name|elevation_ft|continent|iso_country|iso_region|municipality|gps_code|iata_code|local_code|         coordinates|\n",
      "+-----+-------------+--------------------+------------+---------+-----------+----------+------------+--------+---------+----------+--------------------+\n",
      "|  00A|     heliport|   Total Rf Heliport|          11|       NA|         US|     US-PA|    Bensalem|     00A|     null|       00A|-74.9336013793945...|\n",
      "| 00AA|small_airport|Aero B Ranch Airport|        3435|       NA|         US|     US-KS|       Leoti|    00AA|     null|      00AA|-101.473911, 38.7...|\n",
      "| 00AK|small_airport|        Lowell Field|         450|       NA|         US|     US-AK|Anchor Point|    00AK|     null|      00AK|-151.695999146, 5...|\n",
      "| 00AL|small_airport|        Epps Airpark|         820|       NA|         US|     US-AL|     Harvest|    00AL|     null|      00AL|-86.7703018188476...|\n",
      "| 00AR|       closed|Newport Hospital ...|         237|       NA|         US|     US-AR|     Newport|    null|     null|      null| -91.254898, 35.6087|\n",
      "| 00AS|small_airport|      Fulton Airport|        1100|       NA|         US|     US-OK|        Alex|    00AS|     null|      00AS|-97.8180194, 34.9...|\n",
      "| 00AZ|small_airport|      Cordes Airport|        3810|       NA|         US|     US-AZ|      Cordes|    00AZ|     null|      00AZ|-112.165000915527...|\n",
      "| 00CA|small_airport|Goldstone /Gts/ A...|        3038|       NA|         US|     US-CA|     Barstow|    00CA|     null|      00CA|-116.888000488, 3...|\n",
      "| 00CL|small_airport| Williams Ag Airport|          87|       NA|         US|     US-CA|       Biggs|    00CL|     null|      00CL|-121.763427, 39.4...|\n",
      "| 00CN|     heliport|Kitchen Creek Hel...|        3350|       NA|         US|     US-CA| Pine Valley|    00CN|     null|      00CN|-116.4597417, 32....|\n",
      "+-----+-------------+--------------------+------------+---------+-----------+----------+------------+--------+---------+----------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_airport_code = spark.read.csv('./airport-codes_csv.csv', header=True)\n",
    "df_airport_code.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "if show_data:\n",
    "    print(\"total records:\", df_airport_code.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# check null record\n",
    "if show_data:\n",
    "    df_airport_code.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in df_airport_code.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_airport_code_schema = StructType([\n",
    "    StructField('ident', StringType(), True),\n",
    "    StructField('type', StringType(), True),\n",
    "    StructField('name', StringType(), True),\n",
    "    StructField('elevation_ft', IntegerType(), True),\n",
    "    StructField('continent', StringType(), True),\n",
    "    StructField('iso_country', StringType(), True),\n",
    "    StructField('iso_region', StringType(), True),\n",
    "    StructField('municipality', StringType(), True),\n",
    "    StructField('gps_code', StringType(), True),\n",
    "    StructField('iata_code', StringType(), True),\n",
    "    StructField('local_code', StringType(), True),\n",
    "    StructField('coordinates', StringType(), True)\n",
    "])\n",
    "\n",
    "df_airport_code = spark.read.csv('./airport-codes_csv.csv', schema=df_airport_code_schema, header=True)\n",
    "if show_data:\n",
    "    df_airport_code.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Cleaning Step for Airport Code Dataset\n",
    "- Drop unnecessary columns: AverageTemperatureUncertainty, Latitude, Longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+-----------+----------+------------+--------+----------+\n",
      "|ident|                name|iso_country|iso_region|municipality|gps_code|local_code|\n",
      "+-----+--------------------+-----------+----------+------------+--------+----------+\n",
      "|  00A|   Total Rf Heliport|         US|     US-PA|    Bensalem|     00A|       00A|\n",
      "| 00AA|Aero B Ranch Airport|         US|     US-KS|       Leoti|    00AA|      00AA|\n",
      "| 00AK|        Lowell Field|         US|     US-AK|Anchor Point|    00AK|      00AK|\n",
      "| 00AL|        Epps Airpark|         US|     US-AL|     Harvest|    00AL|      00AL|\n",
      "| 00AR|Newport Hospital ...|         US|     US-AR|     Newport|    null|      null|\n",
      "| 00AS|      Fulton Airport|         US|     US-OK|        Alex|    00AS|      00AS|\n",
      "| 00AZ|      Cordes Airport|         US|     US-AZ|      Cordes|    00AZ|      00AZ|\n",
      "| 00CA|Goldstone /Gts/ A...|         US|     US-CA|     Barstow|    00CA|      00CA|\n",
      "| 00CL| Williams Ag Airport|         US|     US-CA|       Biggs|    00CL|      00CL|\n",
      "| 00CN|Kitchen Creek Hel...|         US|     US-CA| Pine Valley|    00CN|      00CN|\n",
      "+-----+--------------------+-----------+----------+------------+--------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_airport_code = df_airport_code.drop(*['type', 'elevation_ft', 'continent', 'coordinates', 'iata_code'])\n",
    "df_airport_code.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Create df_world_average_temp dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------------------+\n",
      "|    Country|avg(AverageTemperature)|\n",
      "+-----------+-----------------------+\n",
      "|       Chad|     27.189829394812683|\n",
      "|     Russia|       3.34726798287354|\n",
      "|   Paraguay|     22.784014312977117|\n",
      "|      Yemen|      25.76840766445382|\n",
      "|    Senegal|      25.98417669449083|\n",
      "|     Sweden|      5.665518003790279|\n",
      "|     Guyana|      26.54984937439856|\n",
      "|      Burma|     26.016839989290048|\n",
      "|Philippines|     26.516462467464876|\n",
      "|    Eritrea|     24.001515877771144|\n",
      "|   Djibouti|     29.152790108564506|\n",
      "|   Malaysia|      26.43475662438397|\n",
      "|  Singapore|     26.523102826510677|\n",
      "|     Turkey|     12.951888167466654|\n",
      "|     Malawi|      21.34787202649805|\n",
      "|       Iraq|     19.884738137449155|\n",
      "|    Germany|      8.482790790263826|\n",
      "|Afghanistan|     13.816496896263578|\n",
      "|   Cambodia|     26.918136297728335|\n",
      "|     Jordan|     18.360980886539238|\n",
      "+-----------+-----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_world_avg_temp = df_world_temp.select(['Country', 'AverageTemperature']).groupBy('Country').avg()\n",
    "df_world_avg_temp.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "![erd](./erd.png)\n",
    "\n",
    "- The Data Model has 6 tables, includes a fact table (**i94 table**) and 5 dimension tables:\n",
    "    - us_cities_demographics table\n",
    "    - airport table\n",
    "    - visa_type table\n",
    "    - immigrate_type table\n",
    "    - country_temp table\n",
    "    \n",
    "- The architecture follows by Star Schema    \n",
    "\n",
    "#### 3.2 Mapping Out Data Pipelines\n",
    "- i94 table\n",
    "    - use source from `../../data/18-83510-I94-Data-2016/*.sas7bdat`\n",
    "    - read as `sas7bdat` format\n",
    "    - define type data of columns\n",
    "    \n",
    "    - drop columns:\n",
    "        - occup\n",
    "        - entdepu\n",
    "        - insnum\n",
    "        - dtadfile\n",
    "        - visapost\n",
    "        - entdepa\n",
    "        - entdepd\n",
    "        - dtaddto\n",
    "        - count\n",
    "        - delete_days\n",
    "        - delete_mexl\n",
    "        - delete_dup\n",
    "        - delete_visa\n",
    "        - delete_recdup\n",
    "        - validres\n",
    "        \n",
    "    - change null or abnormal value to exception value on:\n",
    "        - matflag\n",
    "        - i94mode\n",
    "        \n",
    "    - change date time datatype on:\n",
    "        - arrdate\n",
    "        - depdate\n",
    "        \n",
    "- us_cities_demographics table\n",
    "    - use source from `./us-cities-demographics.csv`\n",
    "    - read as `csv` format\n",
    "    - define type data of columns\n",
    "    - drop columns:\n",
    "        - number_of_veterans\n",
    "        - foreign_born\n",
    "        - average_household_size\n",
    "        - race\n",
    "        - count    \n",
    "    \n",
    "- airport table\n",
    "    - use source from `./airport-codes_csv.csv`\n",
    "    - read as `csv` format\n",
    "    - define type data of columns\n",
    "    - drop columns:\n",
    "        - type\n",
    "        - elevation_ft\n",
    "        - continent\n",
    "        - coordinates\n",
    "        - iata_code\n",
    "\n",
    "- visa_type table\n",
    "    - use source from `I94_SAS_Labels_Descriptions.SAS` file\n",
    "    - modify and save to csv \n",
    "    - read as `csv` format\n",
    "    \n",
    "- immigrate_type table\n",
    "    - use source from `I94_SAS_Labels_Descriptions.SAS` file\n",
    "    - modify and save to csv \n",
    "    - read as `csv` format\n",
    "    \n",
    "- country_temp table\n",
    "    - use temperature data from `../../data2/GlobalLandTemperaturesByCity.csv` \n",
    "    - calculate average temperature\n",
    "    - use `country_name` from `I94_SAS_Labels_Descriptions.SAS` file\n",
    "    - use `country_code` from `i94` table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model\n",
    "Build the data pipelines to create the data model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>country_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>582</td>\n",
       "      <td>MEXICO Air Sea-and Not Reported (I-94-no land ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>236</td>\n",
       "      <td>AFGHANISTAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101</td>\n",
       "      <td>ALBANIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>316</td>\n",
       "      <td>ALGERIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>102</td>\n",
       "      <td>ANDORRA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   code                                       country_name\n",
       "0   582  MEXICO Air Sea-and Not Reported (I-94-no land ...\n",
       "1   236                                        AFGHANISTAN\n",
       "2   101                                            ALBANIA\n",
       "3   316                                            ALGERIA\n",
       "4   102                                            ANDORRA"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country_code_df = pd.read_csv('./country_code.csv')\n",
    "country_code_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_world_avg_temp_pd = df_world_avg_temp.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+---------------+\n",
      "|country_code|        country_name|avg_temperature|\n",
      "+------------+--------------------+---------------+\n",
      "|         392|                MALI|           null|\n",
      "|         243|               BURMA|           null|\n",
      "|         516| TRINIDAD AND TOBAGO|           null|\n",
      "|         251|              ISRAEL|           null|\n",
      "|         255|             LEBANON|           null|\n",
      "|         296|UNITED ARAB EMIRATES|           null|\n",
      "|         472|    MARSHALL ISLANDS|           null|\n",
      "|         322|            DJIBOUTI|           null|\n",
      "|         513|            BARBADOS|           null|\n",
      "|         321|             REUNION|           null|\n",
      "|         375|             BURUNDI|           null|\n",
      "|         108|             DENMARK|           null|\n",
      "|         155|          KAZAKHSTAN|           null|\n",
      "|         368|               EGYPT|           null|\n",
      "|         101|             ALBANIA|           null|\n",
      "|         115|             ICELAND|           null|\n",
      "|         126|            PORTUGAL|           null|\n",
      "|         385|               CONGO|           null|\n",
      "|         412|     SOLOMON ISLANDS|           null|\n",
      "|         688|             BOLIVIA|           null|\n",
      "+------------+--------------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Write code here\n",
    "@udf(StringType())\n",
    "def get_country_name(country_code):\n",
    "    try:\n",
    "        country_name = country_code_df[country_code_df['code']==country_code]['country_name'].iloc[0]\n",
    "        return country_name\n",
    "    except:\n",
    "        return None\n",
    "    \n",
    "@udf(DoubleType())\n",
    "def get_avg_temp(country_name):\n",
    "    try:\n",
    "        temp = df_world_avg_temp_pd[df_world_avg_temp_pd['Country']==country_name].iloc[0,1]\n",
    "\n",
    "        return temp\n",
    "    except:\n",
    "        return None\n",
    "    \n",
    "    \n",
    "def create_country_temp_table(df_immigration):\n",
    "    table = df_immigration.select('i94res').distinct()\n",
    "    \n",
    "    table = table.withColumnRenamed('i94res', 'country_code')\n",
    "    table = table.withColumn('country_name', get_country_name(table.country_code))\n",
    "    table = table.withColumn('avg_temperature', get_avg_temp(table.country_name))\n",
    "    \n",
    "    table.write.parquet(\"country_temp_table\", mode=\"overwrite\")\n",
    "    \n",
    "    return table   \n",
    "\n",
    "country_temp_table = create_country_temp_table(df_immigration)\n",
    "country_temp_table.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+--------------+----------+---------------+-----------------+----------------+----------+\n",
      "|            city|         state|median_age|male_population|female_population|total_population|state_code|\n",
      "+----------------+--------------+----------+---------------+-----------------+----------------+----------+\n",
      "|   Silver Spring|      Maryland|      33.8|          40601|            41862|           82463|        MD|\n",
      "|          Quincy| Massachusetts|      41.0|          44129|            49500|           93629|        MA|\n",
      "|          Hoover|       Alabama|      38.5|          38040|            46799|           84839|        AL|\n",
      "|Rancho Cucamonga|    California|      34.5|          88127|            87105|          175232|        CA|\n",
      "|          Newark|    New Jersey|      34.6|         138040|           143873|          281913|        NJ|\n",
      "|          Peoria|      Illinois|      33.1|          56229|            62432|          118661|        IL|\n",
      "|        Avondale|       Arizona|      29.1|          38712|            41971|           80683|        AZ|\n",
      "|     West Covina|    California|      39.8|          51629|            56860|          108489|        CA|\n",
      "|        O'Fallon|      Missouri|      36.0|          41762|            43270|           85032|        MO|\n",
      "|      High Point|North Carolina|      35.5|          51751|            58077|          109828|        NC|\n",
      "|          Folsom|    California|      40.9|          41051|            35317|           76368|        CA|\n",
      "|          Folsom|    California|      40.9|          41051|            35317|           76368|        CA|\n",
      "|    Philadelphia|  Pennsylvania|      34.1|         741270|           826172|         1567442|        PA|\n",
      "|         Wichita|        Kansas|      34.6|         192354|           197601|          389955|        KS|\n",
      "|         Wichita|        Kansas|      34.6|         192354|           197601|          389955|        KS|\n",
      "|      Fort Myers|       Florida|      37.3|          36850|            37165|           74015|        FL|\n",
      "|      Pittsburgh|  Pennsylvania|      32.9|         149690|           154695|          304385|        PA|\n",
      "|          Laredo|         Texas|      28.8|         124305|           131484|          255789|        TX|\n",
      "|        Berkeley|    California|      32.5|          60142|            60829|          120971|        CA|\n",
      "|     Santa Clara|    California|      35.2|          63278|            62938|          126216|        CA|\n",
      "+----------------+--------------+----------+---------------+-----------------+----------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def create_us_cities_demographics_table(df_us_city):\n",
    "    table = df_us_city.drop(*['number_of_veterans', 'foreign_born', 'average_household_size', 'race', 'count'])\n",
    "    \n",
    "    table.write.parquet(\"us_cities_demographics_table\", mode=\"overwrite\")\n",
    "\n",
    "    return table\n",
    "\n",
    "us_cities_demographics_table = create_us_cities_demographics_table(df_us_city)\n",
    "us_cities_demographics_table.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+-----------+----------+------------+--------+----------+\n",
      "|ident|                name|iso_country|iso_region|municipality|gps_code|local_code|\n",
      "+-----+--------------------+-----------+----------+------------+--------+----------+\n",
      "|  00A|   Total Rf Heliport|         US|     US-PA|    Bensalem|     00A|       00A|\n",
      "| 00AA|Aero B Ranch Airport|         US|     US-KS|       Leoti|    00AA|      00AA|\n",
      "| 00AK|        Lowell Field|         US|     US-AK|Anchor Point|    00AK|      00AK|\n",
      "| 00AL|        Epps Airpark|         US|     US-AL|     Harvest|    00AL|      00AL|\n",
      "| 00AR|Newport Hospital ...|         US|     US-AR|     Newport|    null|      null|\n",
      "| 00AS|      Fulton Airport|         US|     US-OK|        Alex|    00AS|      00AS|\n",
      "| 00AZ|      Cordes Airport|         US|     US-AZ|      Cordes|    00AZ|      00AZ|\n",
      "| 00CA|Goldstone /Gts/ A...|         US|     US-CA|     Barstow|    00CA|      00CA|\n",
      "| 00CL| Williams Ag Airport|         US|     US-CA|       Biggs|    00CL|      00CL|\n",
      "| 00CN|Kitchen Creek Hel...|         US|     US-CA| Pine Valley|    00CN|      00CN|\n",
      "| 00CO|          Cass Field|         US|     US-CO|  Briggsdale|    null|      null|\n",
      "| 00FA| Grass Patch Airport|         US|     US-FL|    Bushnell|    00FA|      00FA|\n",
      "| 00FD|  Ringhaver Heliport|         US|     US-FL|   Riverview|    00FD|      00FD|\n",
      "| 00FL|   River Oak Airport|         US|     US-FL|  Okeechobee|    00FL|      00FL|\n",
      "| 00GA|    Lt World Airport|         US|     US-GA|    Lithonia|    00GA|      00GA|\n",
      "| 00GE|    Caffrey Heliport|         US|     US-GA|       Hiram|    00GE|      00GE|\n",
      "| 00HI|  Kaupulehu Heliport|         US|     US-HI| Kailua/Kona|    00HI|      00HI|\n",
      "| 00ID|Delta Shores Airport|         US|     US-ID|  Clark Fork|    00ID|      00ID|\n",
      "| 00IG|       Goltl Airport|         US|     US-KS|    McDonald|    00IG|      00IG|\n",
      "| 00II|Bailey Generation...|         US|     US-IN|  Chesterton|    00II|      00II|\n",
      "+-----+--------------------+-----------+----------+------------+--------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def create_airport_table(df_airport_code):\n",
    "    table = df_airport_code\n",
    "    \n",
    "    table.write.parquet(\"airport_table\", mode=\"overwrite\")\n",
    "\n",
    "    return table\n",
    "\n",
    "airport_table = create_airport_table(df_airport_code)\n",
    "airport_table.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+\n",
      "|type|    name|\n",
      "+----+--------+\n",
      "|   1|Business|\n",
      "|   2|Pleasure|\n",
      "|   3| Student|\n",
      "+----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def create_visa_type_table(path='./visa_category.csv'):\n",
    "    table = spark.read.csv(path, header=True)\n",
    "    \n",
    "    table.write.parquet(\"visa_type_table\", mode=\"overwrite\")\n",
    "\n",
    "    return table\n",
    "\n",
    "visa_type_table = create_visa_type_table('./visa_category.csv')\n",
    "visa_type_table.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------+\n",
      "|type|        name|\n",
      "+----+------------+\n",
      "|   1|         Air|\n",
      "|   2|         Sea|\n",
      "|   3|        Land|\n",
      "|   9|Not reported|\n",
      "+----+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def create_immigrate_type_table(path='./immigrate_type.csv'):\n",
    "    table = spark.read.csv(path, header=True)\n",
    "    \n",
    "    table.write.parquet(\"immigrate_type_table\", mode=\"overwrite\")\n",
    "    \n",
    "    return table\n",
    "\n",
    "immigrate_type_table = create_immigrate_type_table('./immigrate_type.csv')\n",
    "immigrate_type_table.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+------+------+------+-------+----------+-------+-------+----------+------+-------+-------+-------+------+-------+-----------+-----+--------+\n",
      "|cicid|i94yr|i94mon|i94cit|i94res|i94port|   arrdate|i94mode|i94addr|   depdate|i94bir|i94visa|matflag|biryear|gender|airline|     admnum|fltno|visatype|\n",
      "+-----+-----+------+------+------+-------+----------+-------+-------+----------+------+-------+-------+-------+------+-------+-----------+-----+--------+\n",
      "|    6| 2016|     4|   692|   692|    XXX|2016-04-29|      9|   null|      null|    37|      2|  false|   1979|  null|   null| 1897628485| null|      B2|\n",
      "|    7| 2016|     4|   254|   276|    ATL|2016-04-07|      1|     AL|      null|    25|      3|  false|   1991|     M|   null| 3736796330|00296|      F1|\n",
      "|   15| 2016|     4|   101|   101|    WAS|2016-04-01|      1|     MI|2016-08-25|    55|      2|   true|   1961|     M|     OS|  666643185|   93|      B2|\n",
      "|   16| 2016|     4|   101|   101|    NYC|2016-04-01|      1|     MA|2016-04-23|    28|      2|   true|   1988|  null|     AA|92468461330|00199|      B2|\n",
      "|   17| 2016|     4|   101|   101|    NYC|2016-04-01|      1|     MA|2016-04-23|     4|      2|   true|   2012|  null|     AA|92468463130|00199|      B2|\n",
      "|   18| 2016|     4|   101|   101|    NYC|2016-04-01|      1|     MI|2016-04-11|    57|      1|   true|   1959|  null|     AZ|92471038030|00602|      B1|\n",
      "|   19| 2016|     4|   101|   101|    NYC|2016-04-01|      1|     NJ|2016-04-14|    63|      2|   true|   1953|  null|     AZ|92471399230|00602|      B2|\n",
      "|   20| 2016|     4|   101|   101|    NYC|2016-04-01|      1|     NJ|2016-04-14|    57|      2|   true|   1959|  null|     AZ|92471613830|00602|      B2|\n",
      "|   21| 2016|     4|   101|   101|    NYC|2016-04-01|      1|     NY|2016-04-09|    46|      2|   true|   1970|  null|     AZ|92470796030|00602|      B2|\n",
      "|   22| 2016|     4|   101|   101|    NYC|2016-04-01|      1|     NY|2016-04-18|    48|      1|   true|   1968|  null|     AZ|92478489730|00608|      B1|\n",
      "|   23| 2016|     4|   101|   101|    NYC|2016-04-01|      1|     NY|2016-08-05|    52|      2|   true|   1964|  null|     TK|92501394430|00001|      B2|\n",
      "|   24| 2016|     4|   101|   101|    TOR|2016-04-01|      1|     MO|2016-04-10|    33|      2|   true|   1983|  null|     MQ|92490905030|03348|      B2|\n",
      "|   27| 2016|     4|   101|   101|    BOS|2016-04-01|      1|     MA|2016-04-05|    58|      1|   true|   1958|     M|     LH|92478763830|00422|      B1|\n",
      "|   28| 2016|     4|   101|   101|    ATL|2016-04-01|      1|     MA|2016-04-05|    56|      1|   true|   1960|     F|     LH|92478900330|00422|      B1|\n",
      "|   29| 2016|     4|   101|   101|    ATL|2016-04-01|      1|     MA|2016-04-17|    62|      2|   true|   1954|     M|     AZ|92503781430|00614|      B2|\n",
      "|   30| 2016|     4|   101|   101|    ATL|2016-04-01|      1|     NJ|2016-05-04|    49|      2|   true|   1967|     M|     OS|92470209430|00089|      B2|\n",
      "|   31| 2016|     4|   101|   101|    ATL|2016-04-01|      1|     NY|2016-06-06|    43|      2|   true|   1973|     M|     OS|92471289230|00089|      B2|\n",
      "|   33| 2016|     4|   101|   101|    HOU|2016-04-01|      1|     TX|2016-04-10|    53|      2|   true|   1963|     F|     TK|92509301630|00033|      B2|\n",
      "|   34| 2016|     4|   101|   101|    NYC|2016-04-01|      1|     CT|      null|    48|      2|  false|   1968|     M|     AZ|92470420230|00602|      B2|\n",
      "|   35| 2016|     4|   101|   101|    NYC|2016-04-01|      1|     CT|      null|    74|      2|  false|   1942|     F|     TK|  669712185|    1|      B2|\n",
      "+-----+-----+------+------+------+-------+----------+-------+-------+----------+------+-------+-------+-------+------+-------+-----------+-----+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "@udf(IntegerType())\n",
    "def mode_9_immigrate_type(mode):\n",
    "    return 9 if (mode is None or mode == 0) else mode\n",
    "\n",
    "def create_i94_table(df_immigration):\n",
    "    table = df_immigration.withColumn(\"i94mode\", mode_9_immigrate_type(df_immigration[\"i94mode\"]))\n",
    "    \n",
    "    table.write.parquet(\"i94_table\", mode=\"overwrite\")\n",
    "    \n",
    "    return table\n",
    "\n",
    "i94_table = create_i94_table(df_immigration)\n",
    "i94_table.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+------+------+------+-------+-------+-------+-------+-------+------+-------+-------+-------+-------+-------+------+------+--------+\n",
      "|cicid|i94yr|i94mon|i94cit|i94res|i94port|arrdate|i94mode|i94addr|depdate|i94bir|i94visa|matflag|biryear| gender|airline|admnum| fltno|visatype|\n",
      "+-----+-----+------+------+------+-------+-------+-------+-------+-------+------+-------+-------+-------+-------+-------+------+------+--------+\n",
      "|    0|    0|     0| 28575|     0|      0|      0|      0|2027926|3308012|  9517|      0|      0|   9517|4079983|1308066|     0|333922|       0|\n",
      "+-----+-----+------+------+------+-------+-------+-------+-------+-------+------+-------+-------+-------+-------+-------+------+------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i94_table.select([count(when( col(c).isNull(), c)).alias(c) for c in i94_table.columns]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "Explain the data quality checks you'll perform to ensure the pipeline ran as expected. These could include:\n",
    " * Integrity constraints on the relational database (e.g., unique key, data type, etc.)\n",
    " * Unit tests for the scripts to ensure they are doing the right thing\n",
    " * Source/Count checks to ensure completeness\n",
    " \n",
    "Run Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:04<00:00,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check all tables successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tables = ['country_temp_table', 'us_cities_demographics_table', 'airport_table', 'visa_type_table', 'immigrate_type_table', 'i94_table']\n",
    "\n",
    "for table in tqdm.tqdm(tables):\n",
    "    df = spark.read.parquet(table)\n",
    "    records = df.count()\n",
    "    \n",
    "    if records == 0:\n",
    "        raise Exception(\"{} table has 0 record, please check\".format(table))\n",
    "        \n",
    "print(\"Check all tables successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.3 Data dictionary \n",
    "- i94 table\n",
    "| column | type | is_null | description |\n",
    "| - | - | - | - |\n",
    "| cid | int |  | ID |\n",
    "| i94yr | int |  | 4 digit year of arrival |\n",
    "| i94mon | int |  | numeric month of arrival |\n",
    "| i94cit | int | ✅ | 3 digit code for immigrant country of birth |\n",
    "| i94res | int |  | 3 digit code for immigrant country of residence |\n",
    "| i94port | varchar |  | port of arrival |\n",
    "| arrdate | date |  | arrival date in the USA |\n",
    "| i94mode | int |  | type of immigrate |\n",
    "| i94addr | varchar | ✅ | State of arrival in the USA |\n",
    "| depdate | date | ✅ | departure date in the USA |\n",
    "| i94bir | int | ✅ | age of respondent in years |\n",
    "| i94visa | int |  | type of visa |\n",
    "| matflag | boolean |  | match flag of arrdate and depdate |\n",
    "| biryear |int  | ✅ | 4 digit year of birth |\n",
    "| gender | varchar | ✅ | gender code |\n",
    "| airline | varchar | ✅ | airline port of arrival |\n",
    "| admnum | varchar |  | admission number |\n",
    "| fltno | varchar | ✅ | flight number of plane of arrival |\n",
    "| visatype | varchar |  | visa type of admission legally admitting |\n",
    "\n",
    "- us_cities_demographics table\n",
    "| column | type | is_null | description |\n",
    "| - | - | - | - |\n",
    "| city | varchar |  | city name |\n",
    "| state | varchar |  | state name |\n",
    "| median_age | double |  | median age of the city |\n",
    "| male_population | int | ✅ | male population of the city |\n",
    "| female_population | int | ✅ | female population of the city |\n",
    "| total_population | int |  | total population of the city |\n",
    "| state_code | varchar |  | state code in the USA |\n",
    "\n",
    "- airport table\n",
    "| column | type | is_null | description |\n",
    "| - | - | - | - |\n",
    "| ident | varchar |  | ID |\n",
    "| name | varchar |  | airport name |\n",
    "| iso_country | varchar |  | country code of airport |\n",
    "| iso_region | varchar |  | region code of airport |\n",
    "| municipality | varchar | ✅ | city of airport |\n",
    "| gps_code | varchar | ✅ | gps code of airport |\n",
    "| local_code | varchar | ✅ | local code of airport |\n",
    "\n",
    "- visa_type table\n",
    "| column | type | is_null | description |\n",
    "| - | - | - | - |\n",
    "| type | int |  | visa type code |\n",
    "| name | varchar |  | visa type |\n",
    "\n",
    "- immigrate_type table\n",
    "| column | type | is_null | description |\n",
    "| - | - | - | - |\n",
    "| type | int |  | immigrate type code |\n",
    "| name | varchar |  | immigrate type |\n",
    "\n",
    "- country_temp table\n",
    "| column | type | is_null | description |\n",
    "| - | - | - | - |\n",
    "| country_code | int |  | country code |\n",
    "| country_name | varchar |  | country name |\n",
    "| avg_temperature | double | ✅ | average temperature of country |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Step 5: Complete Project Write Up\n",
    "- The choice of tools and technologies for the project?\n",
    "    - PySpark: PySpark run faster than Pandas with the large dataset, also PySpark calculate data as dataframe, friendly and easy to use\n",
    "    - Parquet file: save data as parquet file is so fast, easy to read and modify as dataframe. With large dataset, parquet is faster than csv, json or other text file.\n",
    "    \n",
    "- How often the data should be updated and why?\n",
    "    - i94 table: the table get by each month -> should update each month by load the new file \n",
    "    - visa_type and immigrate_type tables: only update when have new type, so dont need to update frequently\n",
    "    - country_temp table: if you need to update the new average temperature of the country, you could update frequently\n",
    "    - airport_code table: you dont need to update frequently\n",
    "    - us_cities_demographics table: the change is in population columns, so if you dont need to update the information about the population of the city, you dont need to update the table\n",
    "    \n",
    "- Write a description of how you would approach the problem differently under the following scenarios:\n",
    " - The data was increased by 100x?\n",
    "     Run Spark with multy nodes, like AWS S3, AWS RedShift, with multi node and it increase the performance of the system, so the data process faster \n",
    " \n",
    " - The data populates a dashboard that must be updated on a daily basis by 7am every day?\n",
    "     The most changed data is in country_temperature and i94 table, it is not a problem if the data need to run daily\n",
    "     \n",
    " - The database needed to be accessed by 100+ people?\n",
    "     Move database to AWS Redshift because it supports more than 100 access+ people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "!rm -rf airport_table country_temp_table i94_table immigrate_type_table sas_data us_cities_demographics_table visa_type_table"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
